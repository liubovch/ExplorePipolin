{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Abricate analysis of pipolin-containing strains\n",
    "\n",
    "### Author: Liubov Chuprikova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import modules\n",
    "import os\n",
    "import subprocess\n",
    "import pandas\n",
    "import numpy\n",
    "from utilities import check_dir\n",
    "import sys\n",
    "sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# functions and variables\n",
    "ABRICATE_PATH = '/home/liubov/repos/abricate/bin/abricate'\n",
    "GENOMES_PATH = '/home/liubov/Documents/tfm/the_whole_analysis/all_genomes'\n",
    "WORKING_DIR = '/home/liubov/Documents/tfm/the_whole_analysis/abricate_analysis'\n",
    "\n",
    "def get_abricate_databases():\n",
    "    \"\"\"\n",
    "    Run `abricate --list` and parse available databases from stdout.\n",
    "    \"\"\"\n",
    "    abricate_list = subprocess.run([ABRICATE_PATH, '--list'],\n",
    "                                   stdout=subprocess.PIPE, \n",
    "                                   stderr=subprocess.STDOUT).stdout.decode('utf-8')\n",
    "    databases = []\n",
    "    for line in abricate_list.split('\\n'):\n",
    "        entry = line.split('\\t')[0]\n",
    "        if entry != 'DATABASE' and entry != '':\n",
    "            databases.append(entry)\n",
    "    return databases\n",
    "\n",
    "def run_abricate(database_dir, genomes_dir):\n",
    "    \"\"\"\n",
    "    Screen all the genomes in the genomes_dir against the given database.\n",
    "    \"\"\"\n",
    "    snp_databases = ['fumC', 'fimH', 'pointFinder_Ecoli']\n",
    "    db = os.path.basename(database_dir)\n",
    "    minid = '100' if db in snp_databases else '75'\n",
    "    mincov = '100' if db in snp_databases else '0'\n",
    "    in_genomes = os.listdir(genomes_dir)\n",
    "    os.mkdir(database_dir)\n",
    "    for genome in in_genomes:\n",
    "        with open(os.path.join(database_dir, f'{genome[:-3]}.tab', ), 'w') as ouf:\n",
    "            subprocess.run([ABRICATE_PATH, '--db', db, \n",
    "                            '--minid', minid, '--mincov', mincov,\n",
    "                            '--threads', '4', '--nopath', \n",
    "                            f'{os.path.join(genomes_dir, genome)}'], stdout=ouf)\n",
    "\n",
    "def abricate_summarize(databases, out_dir):\n",
    "    summaries_dir = os.path.join(out_dir, 'summaries')\n",
    "    check_dir(summaries_dir)   # create if not exists\n",
    "    for db in databases:\n",
    "        db_out_path = os.path.join(out_dir, db)\n",
    "        if not os.path.isdir(db_out_path):\n",
    "            continue\n",
    "        if os.path.isfile(os.path.join(summaries_dir, f'{db}.tab')):\n",
    "            continue\n",
    "        db_out_files = ' '.join([os.path.join(db_out_path, file) for file in os.listdir(db_out_path)])\n",
    "        with open(os.path.join(summaries_dir, f'{db}.tab'), 'w') as ouf:\n",
    "            subprocess.run(f'{ABRICATE_PATH} --nopath --summary {db_out_files}',\n",
    "                           shell=True, stdout=ouf)\n",
    "\n",
    "def parse_summaries(databases, summaries_dir):\n",
    "    summaries_data = pandas.DataFrame(columns=databases, \n",
    "                                      index=[f'{file[:-3]}.tab' for file in os.listdir(GENOMES_PATH)])\n",
    "    for db in databases:\n",
    "        summary_file = os.path.join(summaries_dir, f'{db}.tab')\n",
    "        if not os.path.isfile(summary_file):\n",
    "            continue\n",
    "        with open(summary_file) as inf:\n",
    "            for line in inf:\n",
    "                if line[0] != '#':\n",
    "                    genome, number = line.strip().split(sep='\\t')[:2]\n",
    "                    summaries_data.at[genome, db] = number\n",
    "\n",
    "    return summaries_data\n",
    "\n",
    "def set_chtype(from_df, to_df, chtype):\n",
    "    for _, row in from_df.iterrows():\n",
    "        entry = row['#FILE']\n",
    "        index_array = numpy.flatnonzero(row == 100)\n",
    "        if len(index_array) > 1:\n",
    "            raise AssertionError('More than a single variation locus was defined!')\n",
    "        if len(index_array) == 0:\n",
    "            entry_type = numpy.nan\n",
    "        else:\n",
    "            entry_type = row.index[index_array[0]]\n",
    "        to_df.at[entry, chtype] = entry_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The analysis\n",
    "### 1. Run abricate with all available databases and summarize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abricate_dbs = get_abricate_databases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for database in abricate_dbs:\n",
    "    db_dir = os.path.join(WORKING_DIR, database)\n",
    "    if not os.path.isdir(db_dir) and database != 'REL-DB'  and database != 'RIP-DB':\n",
    "        run_abricate(db_dir, GENOMES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abricate_summarize(abricate_dbs, WORKING_DIR)\n",
    "summaries = parse_summaries(abricate_dbs, os.path.join(WORKING_DIR, 'summaries'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Define *fimH* and *fumC* types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fimh_summary = pandas.read_csv(os.path.join(WORKING_DIR, 'summaries', 'fimH.tab'), \n",
    "                               sep='\\t', na_values='.')\n",
    "\n",
    "set_chtype(fimh_summary, summaries, 'fimH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fumc_summary = pandas.read_csv(os.path.join(WORKING_DIR, 'summaries', 'fumC.tab'),\n",
    "                               sep='\\t', na_values='.')\n",
    "\n",
    "set_chtype(fumc_summary, summaries, 'fumC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries.to_csv(os.path.join(WORKING_DIR, 'short_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
